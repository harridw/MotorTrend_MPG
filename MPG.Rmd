---
title: "Statistical Inference: MotorTrend_MPG"
author: "EHarris"
date: "7/18/2017"
output: html_document
---

## Packages for Course 7 Project: Motor Trend MPG
```{r setup, include = TRUE, echo = FALSE, results = "hide"}
ipak <- function(pkg){
      new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
      if (length(new.pkg)) 
            install.packages(new.pkg, dependencies = TRUE)
      sapply(pkg, require, character.only = TRUE)
}

### Package Usage
packages <- c("plyr", "dplyr", "data.table", "dtplyr", "lubridate", "ggplot2", "scales",
                  "reshape2", "knitr", "R.cache", "stringr", "gtools", "quantreg",
                  "graphics", "corrplot", "broom")
ipak(packages)
```

## Overview  
You work for Motor Trend, a magazine about the automobile industry. Looking at a data set of a collection of cars, they are interested in exploring the relationship between a set of variables and miles per gallon (MPG) (outcome). They are particularly interested in the following two questions:

* Is an automatic or manual transmission better for MPG?
* Quantify the MPG difference between automatic and manual transmissions"  

A first step in the analysis is to look at the effect of transmission type, automatic vs. manual, on miles per gallon (MPG).  Without much review of the dataset, it may be reasonable to expect that a manual transmission vehicle is associated with higher MPG.  Further review will uncover other items, such as vehicle weight and the number of cylinders (e.g. 4, 6, 8), that may contribute more significantly to the mileage of a vehicle.


## Load Data  
Given that this is an R dataset we can simply use data(ToothGrowth) to load the dataset into the current enviromnent.  
```{r load_mtcars, include = TRUE, echo = TRUE}
data(mtcars)
mtcars$am <- as.factor(mtcars$am)
mtcars$cyl <- as.factor(mtcars$cyl)

```


## Exploratory Data Analysis  
Our exploratory analysis provides some quick insigtht to the data of 'mtcars' data set.  We provide a chart of the correlation for each variable and two panel plots.  One of the panel plots, representing line graphs of the relationship for each variable, is illustrated in the Appendix.  The other panel plot, illustrated below in Exhibit 2, provides additional information about the relationship of variables to mpg.  The correlation matrix is used to determine which variables are included in the panel plot, based on correlation factor with absolute value > 0.5.


### Summary view of dataset
```{r dataset_overview, include = TRUE, echo = TRUE, results = "hold"}
str(mtcars)
head(mtcars)
summary(mtcars)
```


### Relationship of Variables
Three figures or exhibits are provided in the Appendix to provide insight to the data in 'mtcars'. Figure 1 and Figure 2 compare each of the variables, or terms, in the data set against one another.  Figure 1 provides a panel plot of the relationship between each variable.  Similarly, Figure 2 shows the relationship of each variable in a correlation matrix.

#### Correlation Matrix (Upper Triangle)
This table provides an easy way to look at the relationship between the different variables of the 'mtcars' dataset.  Along the diagonal, we see a value of 1, representing the correlation of a variable(e.g. mpg) and itself.  A correlation factor, or value, is between -1 and 1.  A positive correlation factir indicates that a variable changes directionally with another defined variable.  A negative correlation suggests that two variables move in opposite directions.  The closer the correlation factor is to zero indicates lower correlation.  As correlation moves closer to -1 or 1, the stroger is the correlation or relationship.

#### Plot MPG Relationships
As the focus of the analysis is evaluating drivers or predictors of mpg, Figure 3 plots the relationship of each variable to mpg.  Only 8 variables, rather than 10 available, are illustrated.  The variables excluded from the plots have correlation factor <0.50 (absolute value).  This provides a focus on those variables creating the most influence.


## Regression Analysis
The focus of our analysis is miles per gallon (MPG).  More specifically, we want to understand what variables or terms influence the mpg of a car.  It might be reasonable and/or appropriate to include all variables within the 'mtcars' dataset to predict the mpg of a car.  However, we likely want to explore and understand whether each variable contributes to the estimate.  If we look at the correlation matrix, you can see that the variables 'cyl', 'disp', and 'wt' are similarly correlated with mpg, -0.85, -0.85, and -0.87 respectively.  This strong relationship is further suggested when we look at the correlation factor between these variables: 'cyl'~'disp' = 0.9;  'cyl'~'wt' = 0.78; and 'disp'~'wt' = 0.89.  We'll start with looking at 'mpg' related to the variable 'am', transmission (automatic vs. manual).


### Automatic versus Manual Regression
The initial model looks at the effect of transmission type (automatic vs. manual) on the miles per gallon (MPG) of a car.  It is important to note that the variable 'am' contains a 0 (automatic) or 1 (manual).  So the baseline, or intercept, reflects the average mpg for a car with automatic transmission.  The 'am' coefficient represents the average change in mpg for a car with manual transmission.


#### Exhibit 4: Simple Linear Regression (mpg ~ am)
This simple linear regression produces an intercept of 17.147 mpg.  If the car has a manual transmission, we would estimate an additional 7.25 mpg.  As previously stated, it is idealistic to assume that the type of transmission, automatic vs. manual, could define the mpg of a car.  This is further validated by a relatively low adjusted r.square of 0.3385, meaning that roughly 34% of the change in mpg is explained by transmission type alone.

```{r slr_mpg_am, include = TRUE, echo = TRUE, results = "asis"}
fit1 <- lm(mpg ~ factor(am), data = mtcars)
fit1coef <- round(summary(fit1)$coef, 4)
fit1glance <- round(glance(fit1)[1:6], 4)
fit1coef
fit1glance
```


### Automatic versus Manual (Multivariable Regression)
To build a multivariable regression that best fits the data, we could add one variable, or term, at a time.  The goal is to avoid underfitting or overfitting the model.  Therefore, we want to include variables that minimizes the residual, maximizes adjusted r.square, and statistically significant. We will review our exploratory analysis to add variables, no more than 2 variables at a time.  As transmission (automatic vs. manual) is a key variable of the analysis, it is retained in all regression models developed.


#### Exhibit 5: Multivariable Regression (mpg ~ am + wt)
The next variable we add to the regression model is 'wt'.  This variable has highest correlation, -0.87, with mpg.  This model produces an adjusted r.square of 0.7358, explaining more than twice as much of the mpg variation than transmission (automatic vs. manual) alone.  The residual squared error (sigma) is also reduced from 4.9 to 3.1.  The addition of 'wt' also changes the coefficients for the intercept and transmission (manual)

```{r mlr_am_plus_one, include = TRUE, echo = TRUE, results = "asis"}
fit2 <- lm(mpg ~ factor(am) + wt, data = mtcars)
fit2coef <- round(summary(fit2)$coef, 4)
fit2glance <- round(glance(fit2)[1:6], 4)
fit2coef
fit2glance
```

#### Exhibit 6: Multivariable Regression (mpg ~ am + wt + cyl)
In the following regression model, we added the variable 'cyl' as a factor, due to limited number of discrete values (4, 6, 8).  This regression model improves the adjusted r.square to 0.8134 and reduces the residual (sigma) to 2.6032 while maintaining p-value = 0 (rounded to 4 decimal places).  Each of the additional variables (wt, cyl6, cyl8) is significant at the 0.05 threshold.

```{r mlr_am_plus_two, include = TRUE, echo = TRUE, results = "asis"}
fit3 <- lm(mpg ~ factor(am) + wt + factor(cyl), data = mtcars)
fit3coef <- round(summary(fit3)$coef, 4)
fit3glance <- round(glance(fit3)[1:6], 4)
fit3coef
fit3glance
```

```{r mlr_am_plus_three_elim, include = FALSE, echo = FALSE, results = "hide"}
fit4E <- lm(mpg ~ factor(am) + wt + factor(cyl) + drat, data = mtcars)
fit4Ecoef <- round(summary(fit4E)$coef, 4)
fit4Eglance <- round(glance(fit4E)[1:6], 4)
fit4Ecoef
fit4Eglance
```

#### Exhibit 7: Multivariable Regression (mpg ~ am + wt + cyl + hp)
In this regression model, we add the variable 'hp'.  Besides 'drat' this variable has the most significant correlation with mpg of the remaining variables.  The variable 'drat' was considered.  However, it failed to meet several important criteria, specifically:  input p-value 0.8613 not significant; adjusted r.square decreases rather than increase; and the residual (sigma) increases rather than decrease.

For reasons indicated above, we selected to add the variable 'hp' to the regression model instead of 'drat'.  The addition of 'hp' improves the adjusted r.square to 0.8401 and reduces the residual to 2.4101.  The only concern is the effect it has on factor(cyl)8.  Intuitively, we would expect the coeffient for 'cyl8' to reduce mpg more than 'cyl6'.  This implies a different interaction between 'hp' and 'cyl8'.  As a result, the p-value, 0.3523, for factor(cyl)8 is no longer significant at 0.05 level.

```{r mlr_am_plus_three, include = TRUE, echo = TRUE, results = "asis"}
fit4 <- lm(mpg ~ factor(am) + wt + factor(cyl) + hp, data = mtcars)
fit4coef <- round(summary(fit4)$coef, 4)
fit4glance <- round(glance(fit4)[1:6], 4)
fit4coef
fit4glance
```


#### Exhibit 8: Multivariable Regression (include all independent variables)
The purpose of this exhibit is to explore a regression model that includes all variables, or terms, in the 'mtcars' data set.  Although we did not include an variables as a factor, it is clear that including all variables does not produce a better model.  The adjusted r.square and residual are both worse than including only the vaiables am, wt, cyl (factor), and hp.  Additionally, each of the variables has a p-value that is not significant at 0.05 level. 
```{r slr_mpg_am_nine, include = TRUE, echo = TRUE, results = "asis"}
fit10 <- lm(mpg ~ ., data = mtcars)
fit10coef <- round(summary(fit10)$coef, 4)
fit10glance <- round(glance(fit10)[1:6], 4)
fit10coef
fit10glance
```


#### Exhibit 9: ANOVA
The findings provided below for Model 4: mpg ~ factor(am) + wt + factor(cyl) + hp produce a p-value of 0.026935, which indicates that this model is significant.  These variables further contribute to the accuracy of the model.

```{r}
mpg.anova <- anova(fit1, fit2, fit3, fit4)
mpg
```


## Residuals & Diagnostics

```{r plot_residuals, fig.keep = "high", fig.show = "asis", fig.path = 'figure/'}
par(mfrow = c(2,2))
plot(fit4)
```


#### Residuals vs Fitted
This plot shows if residuals have non-linear patterns. The fact that the residuals are fairly well-distributed around the fitted line, and no particular pattern, we are fairly confident that the selected regression model is a relatively good fit.  There are not 


#### Residuals vs Fitted
This plot shows if residuals are normally distributed. It’s good fit if residuals are lined well on the straight dashed line.  In our plot, the residuals are fairly close to the straight line.  However, there appears to be a little greater distance for outliers, particularly upper right corner.  We may want to explore outliers a little further.


#### Scale-Loation
We use the scale-location plot to check the assumption of equal variance (homoscedasticity).  Ideally, we would see points that are equally spread around a horizontal line along the range of predictors.  Although not a horizontal line, the fitted line does not show much slope up or down.  Additionally, the residual points are fairly evenly distributed about the line, no narrowing or spreading.


#### Residuals vs. Leverage
This is the final plot to examine.  The purpose of this plot is identify "influential" outliers.  If an outlier does not change, maybe minimally changes, the regression line whether it is included or excluded, the outlier is not "influential".  If outliers, residual points, appear in the upper right or lower right corner of the plot, thee points may be influential against the regression line.



## Conclusion
Following our review of Exploratory Data Analysis, it was decided to test two assumptions.  From the boxplot, it appeared that the supplement 'OJ' promoted greater tooth growth than the supplement 'VC'.  It was also apparent that a higher dose promoted greater tooth growth, regardless of supplement introduced.  We chose to test these assumptions by setting NULL hypothesis that there was no difference in the tooth growth for supplement 'OJ' versus 'VC' and a higher dose versus lower dose.  The alternative hypothesis being that 'OJ' promotes greater tooth growth than 'VC' and a higher dose promotes greater tooth growth than a lower dose.

From our t.test, the p-values were rather small, with the exception of testing whether 'OJ' promotes greater tooth growth than 'VC' at a dose = 2.0, indicating that we reject the NULL hypothesis.  In summary, the analysis suggests that 'OJ' promotes greater tooth growth than 'VC'.  Additionally, regardless of the supplement selected, 'OJ' or 'VC', a higher dose of the supplement promotes greater tooth growth than lower dose.

## Appendix
The information provided below is an outline of the request or question driving this assingment and analysis of data for different cars and related miles per gallon (MPG).

### Instructions
You work for Motor Trend, a magazine about the automobile industry. Looking at a data set of a collection of cars, they are interested in exploring the relationship between a set of variables and miles per gallon (MPG) (outcome). They are particularly interested in the following two questions:

“Is an automatic or manual transmission better for MPG”
"Quantify the MPG difference between automatic and manual transmissions"

#### Review criteria

##### Peer Grading
The criteria that your classmates will use to evaluate and grade your work are shown below.
Each criteria is binary: (1 point = criteria met acceptably; 0 points = criteria not met acceptably)

##### Criteria
1. Did the student interpret the coefficients correctly?
2. Did the student do some exploratory data analyses?
3. Did the student fit multiple models and detail their strategy for model selection?
4. Did the student answer the questions of interest or detail why the question(s) is (are) not answerable?
5. Did the student do a residual plot and some diagnostics?
6. Did the student quantify the uncertainty in their conclusions and/or perform an inference correctly?
7. Was the report brief (about 2 pages long) for the main body of the report and no longer than 5 with supporting appendix of figures?
8. Did the report include an executive summary?
9. Was the report done in Rmd (knitr)?


### Figure 1 (Panel Plot): Illustrate the relationship of each variable
This panel plot provides a quick, high-level, illustration of a variable within the dataset against each other variable in the dataset.  The pu
```{r panel_plot_exploratory, fig.keep = "high", fig.show = "asis", fig.path = 'figure/'}
pairs(mtcars, panel = panel.smooth, main = "MT Cars Data", col = 3)
```


#### Figure 2: Correlation Factor Matrix
```{r corr_matrix_grid, include = TRUE, echo = TRUE, results = "asis"}
mtcars.corr <- scale(cor(mtcars))
corr.upper <- upper.tri(mtcars.corr, diag = FALSE)
corr.grid <- round(mtcars.corr*corr.upper,3)
corrplot(mtcars.corr, method = "number", type = "upper", add = FALSE, 
                  order = "original", is.corr = TRUE)
```


#### Figure 3: Variable Relationship to Miles per Gallon (MPG)
This panel plot illustrates the relationship of variables with a high correlation, absolute value > 0.50, with the mpg.  Where it made sense boxplots are used, dotplots in other instances.
```{r panel_plot_high_corr, fig.keep = "high", fig.show = "asis", fig.path = 'figure/'}
par(mfrow = c(2,4), mar = c(6,4,1,1))
g1 <- ggplot(mtcars, aes(x = cyl, y = mpg, group = cyl)) +
            geom_boxplot(width = 0.5) +
            labs(x = "# Cylinders", y = "MPG")
g1
g2 <- ggplot(mtcars, aes(x = disp, y = mpg, group = disp)) +
            geom_dotplot(binaxis = "y", stackdir = "center", dotsize = 0.75, binwidth = 0.5) +
            labs(x = "disp", y = "MPG")
g2
g3 <- ggplot(mtcars, aes(x = hp, y = mpg, group = hp)) +
            geom_dotplot(binaxis = "y", stackdir = "center", dotsize = 0.75, binwidth = 0.5) +
            labs(x = "Horespower", y = "MPG")
g3
g4 <- ggplot(mtcars, aes(x = drat, y = mpg, group = drat)) +
            geom_dotplot(binaxis = "y", stackdir = "center", dotsize = 0.75, binwidth = 0.5) +
            labs(x = "drat", y = "MPG")
g4
g5 <- ggplot(mtcars, aes(x = wt, y = mpg, group = wt)) +
            geom_dotplot(binaxis = "y", stackdir = "center", dotsize = 0.75, binwidth = 0.5) +
            labs(x = "Weight", y = "MPG")
g5
g6 <- ggplot(mtcars, aes(x = vs, y = mpg, group = vs)) +
            geom_boxplot(width = 0.5) +
            labs(x = "vs", y = "MPG")
g6
g7 <- ggplot(mtcars, aes(x = am, y = mpg, group = am)) +
            geom_boxplot(width = 0.5) +
            labs(x = "Auto/Manual", y = "MPG")
g7
g8 <- ggplot(mtcars, aes(x = carb, y = mpg, group = carb)) +
            geom_boxplot(width = 0.5) +
            labs(x = "Carberator", y = "MPG")
g8
```
