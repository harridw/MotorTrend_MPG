myplot2(20)
sleep
range(g1)
range(g2)
difference <- g2 - g1
mean(difference)
sd(difference)
s <- sd(difference)
1.58+c(-1,1)*qt(.975, 9) * s/(9)^.5
mn + c(-1,1)*qt(.975,9)*s/sqrt(10)
t.test(g2, g1, paired = TRUE)
t.test(difference)
t.test(difference)$conf
t.test(difference)$conf.int
sp <- sqrt((7 * 15.34^2 + 20 * 18.23^2) / (8 + 21 -2))
sp <- 7 * 15.34^2 + 20 * 18.23^2
27
8+21-2
ns <- 8+21-2
sp <- (sp / ns)^.5
sp <- sqrt(sp / ns)
132.86 – 127.44 + c(-1, 1) * qt(.975, 27) * sp *sqrt(1/8 + 1/21)
132.86 – 127.44 + c(-1, 1) * qt(.975, 27) * sp *sqrt(1/8 + 1/21)
132.86
132.86-127.44+c(-1,1)*qt(.975,ns)*sp*sqrt(1/8+1/21)
var(g1+g2, 10+10-2)
var(g1)
sp <- sqrt((9*var(g1)+9*var(g2))/18)
3
md + c(-1,1)*qt(.975,18)*sp*sqrt(1/5)
3
t.test(g2,g1,paired=FALSE,var.equal=TRUE)$conf
t.test(g2,g1,paired=TRUE,var.equal=TRUE)$conf
Pretty cool that it matches, right? Note that 0 is again in this 95%
| interval so you can't reject the claim that the two groups are the same.
| (Recall that this is the opposite of what we saw with paired data.) Let's
| run t.test again, this time with paired=TRUE and see how different the
| result is. Don't specify var.equal and look only at the confidence
| interval
t.test(g2,g1,paired=TRUE)$conf
num <- (15.34^2/8 + 18.23^2/21)
num <- (15.34^2/8 + 18.23^2/21)^2
den <- ((15.34^4/8^2)/7+(18.23^4/21^2)/20)
mydf <- num / den
qt(.975, mydf)
132.86-127.44 +c(-1,1)*qt(.975,mydf)*sqrt(15.34^2/8 + 18.23^2/21)
swirl()
1
2
0.8
15
qt(.95,15)
dim(fs)
t.test(fs$sheight - fs$fheight)
11.7885 * sd(fs$sheight-fs$fheight)/sqrt(1078)
mybin
7
7.8
mybin(7.8)
info
skip()
library(swirl)
swirl()
pt(2.5, 15, lower.tail = FALSE)
qnorm(.95, 2, lower.tail = FALSE)
qnorm(.95)
qnorm(.99)
pnorm(q = 2, mean = 0, sd = 1, lower.tail = TRUE, log.p = FALSE)
pnorm(q = 2, mean = 0, sd = 1, lower.tail = FALSE, log.p = FALSE)
mybin
pbinom(6, size = 8, prob = 0.5, lower.tail = FALSE)
pbinom(7,8, prob = 0.5, lower.tail = TRUE, log.p = FALSE)
ppois(9,100*.05, lower.tail = FALSE)
ppois(9, 5, lower.tail = FALSE)
qt(.95, 8)
qt(.975, 8)
1100+c(-1,1)*2.306*(30/(9^.5))
t.test(-2, 9)
pt(.95, 9)
.6^.5
.68^.5
qt(.975, 18)
(9*.6+9*.68)/18
0.64^.5
(1/10 +1/10)^.5
.8*(1/10 +1/10)^.5
2.100922*.8*(1/10 +1/10)^.5
-2+2.100922*.8*(1/10 +1/10)^.5
-2-2.100922*.8*(1/10 +1/10)^.5
(99*.25+99*4)/198
(1/100 + 1/100)^.5
2.125*(1/100 + 1/100)^.5
2.125*0.3005204+2
1.96*0.3005204+2
2-1.96*0.3005204
pt(2.5, 4)
pt(97.5, 4)
pt(2.5, 4, lower.tail = FALSE)
qnorm(.95)
sub_id <- c(1,2,3,4,5)
baseline <- c(140,138,150,148,135)
week2 <- c(132, 135, 151, 146, 130)
BP <- cbind(sub_id, baseline, week2)
BP
t.test(BP$week2-BP$baseline)
BP <- as.data.frame(BP)
t.test(BP$week2-BP$baseline)
mean(BP$baseline)
mean(BP$week2)
BP
(1-.75)^2
(0-.75)^2
(.0625*3+.5625)/4
((.0625*3+.5625)/4)^.5
.5/.4330127
pnorm(0.75, mean = 0.5, sd = 0.4330127/sqrt(4)
)
pt(.95, 3, lower.tail = FALSE)
?pt
pt(.95, 3, lower.tail = TRUE)
pt(1.154701, 3)
x <- c(1,1,1,0)
t.test(x)
?power.t.test
100^.5 * (.01 - 0)/.04
power.t.test(n = 100, delta = .01, sd = .04, sig.leve = 0.05, power = 2.5, type = "one.sample", alternative = "one.sided")
power.t.test(n = 100, delta = .01, sd = .04, sig.leve = 0.05, power = NULL, type = "one.sample", alternative = "one.sided")
power.t.test(n = 100, delta = .01, sd = .04, sig.leve = 0.1, power = NULL, type = "one.sample", alternative = "one.sided")
power.t.test(n = 100, delta = .01, sd = .04, sig.leve = 0.1, power = NULL, type = "one.sample", alternative = "two.sided")
power.t.test(n = NULL, delta = .01, sd = .04, sig.level = 0.1, power = .90, type = "one.sample", alternative = "two.sided")
power.t.test(n = 100, delta = .01, sd = .04, sig.level = 0.05, power = NULL, type = "one.sample", alternative = "one.sided")
power.t.test(n = NULL, delta = .01, sd = .04, sig.level = 0.1, power = .90, type = "one.sample", alternative = "one.sided")
power.t.test(n = NULL, delta = .01, sd = .04, sig.level = 0.5, power = .90, type = "one.sample", alternative = "one.sided")
power.t.test(n = NULL, delta = .01, sd = .04, sig.level = 0.05, power = .90, type = "one.sample", alternative = "one.sided")
power.t.test(n = NULL, delta = .01, sd = .04, sig.level = 0.05, power = .90, type = "one.sample", alternative = "two.sided")
qt(.95, 3)
?pnorm
pnorm(2.353363, mean = 0.75, sd = 0.4330127, lower.tail = FALSE)
pnorm(2.353363, mean = 0.5, sd = 0.4330127, lower.tail = FALSE)
dt(1.154701, 3)
pt(1.154701, 3)
dt(1.154701, 3)*2
?pbinom
?binom.test
binom.test(x = 3, n = 4, p = 0.5, alternative = “greater”, conf.level = 0.95)
binom.test(3, 4, 0.5, alternative="greater", conf.level = 0.95)
poisson.test(10, 1787, 1/100, alternative = “greater”, conf.level = 0.95)
poisson.test(10, 1787, 1/100, alternative =“greater”, conf.level = 0.95)
poisson.test(10, 1787, 1/100, alternative = "greater", conf.level = 0.95)
poisson.test(10, 1787, 1/100, alternative = "less", conf.level = 0.95)
lambda <- 0.2
mu <- 1/lambda
sig <- 1/lambda
vars <- sig^2
set.seed(100)
n1 <- 10000                                   ## Large Sample, number of random exponential observations
lrg.sample <- data.frame(rating = c(rexp(n1, lambda)))
sample.mean <- round(mean(lrg.sample$rating), 3)   ## Population Mean
sample.var <- for (i in 1: n1) sum((lrg.sample$rating[i] - sample.mean)^2)/(n1-1)
sample.var <- for (i in 1: n1) {
sum((lrg.sample$rating[i] - sample.mean)^2)/(n1-1)
}
lrg.sample$rating[1]
(lrg.sample$rating[1]-sample.mean)^2
sum.var <- for (i in 1: n1) {
sum((lrg.sample$rating[i] - sample.mean)^2)
}
for (i in 1: n1) sum.var <- sum((lrg.sample$rating[i] - sample.mean)^2
)
for (i in 1: n1) sum.var <- sum(lrg.sample$rating[i] - sample.mean)^2
for (i in 1: n1) sum.var <- sum((lrg.sample$rating[i] - sample.mean)^2)
=sum.var/9999
sum.var/9999
for (i in 1: n1) sum.var <- sum((lrg.sample$rating[i] - sample.mean)^1)
View(lrg.sample)
(lrg.sample$rating[4]-sample.mean)^2
lrg.sample <- mutate(lrg.sample, diff.square = (rating - sample.mean)^2)
library(dplyr)
lrg.sample <- mutate(lrg.sample, diff.square = (rating - sample.mean)^2)
View(lrg.sample)
sum(lrg.sample$diff.square)/(9999)
sum(lrg.sample$diff.square)/10000
(for (i in 1: n1) sum.var <- sum((lrg.sample$rating[i] - sample.mean)^2))
for (i in 1: n1) sum.var <- sum((lrg.sample$rating[i] - sample.mean)^2))
for (i in 1: n1) sum.var <- sum((lrg.sample$rating[i] - sample.mean)^2)
for (i in 1:n1) sum.var <- sum((lrg.sample$rating[i] - sample.mean)^2)
apply((lrg.sample$rating - sample.mean)^2, sum)
for (i in 1:10000) sum.var <- sum((lrg.sample$rating[i] - sample.mean)^2)
set.seed(100)
n1 <- 10000                                   ## Large Sample, number of random exponential observations
lrg.sample <- data.frame(rating = c(rexp(n1, lambda)))
sample.mean <- round(mean(lrg.sample$rating), 3)   ## Population Mean
lrg.sample <- mutate(lrg.sample, diff.square = (rating - sample.mean)^2)
sample.var <- round(sum(lrg.sample(diff.square)/(n1-1)),3)
sample.var <- round(sum(lrg.sample$diff.square)/(n1-1) ,3)
test.vars = NULL
for (i in 1:10000) test.var <- c(test.var, sum((lrg.sample$rating[i] - sample.mean)^2))
for (i in 1:10000) test.var <- c(test.vars, sum((lrg.sample$rating[i] - sample.mean)^2))
for (i in 1:10000) test.vars <- c(test.vars, sum((lrg.sample$rating[i] - sample.mean)^2))
sum(test.vars)/10000
test.vars = NULL
for (i in 1:10000) test.vars <- c(test.vars, (lrg.sample$rating[i] - sample.mean)^2)
sum(test.vars)/10000
set.seed(100)
nsamp <- 1000
n <- 40
sim.mean = NULL
for (i in 1: nsamp) sim.mean <- c(sim.mean, mean(rexp(n,lambda)))
sim.mean[1]
sim.mean[1000]
hist(sim.mean)
sim.mean <- cumsum(mns) / (1:msims)
plot(sim.mean, type = "l", lwd = 2, col = "black", ylim = c(4,5.5),
xlab = "Number of Simulations",
ylab = "Cumulative Mean",
main = "Sample Mean vs. Theoretical Mean", cex.main = 1.0)
abline(h = 1/mlambda, lwd = 2, col = "red")         ## Line for Theoretical Mean
set.seed(100)
nsamp <- 1000
n <- 40
msim = NULL
for (i in 1: nsamp) msim <- c(msim, mean(rexp(n,lambda)))
msim <- cumsum(mns) / (1:nsamp)
plot(sim.mean, type = "l", lwd = 2, col = "black", ylim = c(4,5.5),
xlab = "Number of Simulations",
ylab = "Cumulative Mean",
main = "Sample Mean vs. Theoretical Mean", cex.main = 1.0)
abline(h = 1/lambda, lwd = 2, col = "red")
sim.mean <- cumsum(msim) / (1:nsamp)
plot(sim.mean, type = "l", lwd = 2, col = "black", ylim = c(4,5.5),
xlab = "Number of Simulations",
ylab = "Cumulative Mean",
main = "Sample Mean vs. Theoretical Mean", cex.main = 1.0)
abline(h = 1/lambda, lwd = 2, col = "red")         ## Line for Theoretical Mean
hist(msim)
hist(msim,
xlab = "Sample Mean",
main = "Histogram for Distribution of Sample Mean")
xnorm <- seq(3, 8, length = 1000)
ynorm <- dnorm(xnorm, mean = 1/lambda, sd = 3)
plot(xnorm, ynorm, type = "l", lwd = 2)
hist(msim,
xlab = "Sample Mean",
main = "Histogram for Distribution of Sample Mean")
lines(seq(min(msim), max(msim), length = 1000),
dnorm(seg(min(msim), max(msim), length = 1000),
mean = 1/lambda, sd = 1/lambda),
col = "blue", lwd = 2)
library(plyr)
lines(seq(min(msim), max(msim), length = 1000),
dnorm(seg(min(msim), max(msim), length = 1000),
mean = 1/lambda, sd = 1/lambda),
col = "blue", lwd = 2)
library(manip)
install.packages("manip")
library(manip)
lines(seq(min(msim), max(msim), length = 1000),
dnorm(seq(min(msim), max(msim), length = 1000),
mean = 1/lambda, sd = 1/lambda),
col = "blue", lwd = 2)
lines(seq(min(msim), max(msim), length = 1000),
dnorm(seq(min(msim), max(msim), length = 100),
mean = 1/lambda, sd = 1/lambda),
col = "blue", lwd = 2)
hist(msim,
xlab = "Sample Mean",
main = "Histogram for Distribution of Sample Mean")
lines(seq(min(msim), max(msim), length = 100),
dnorm(seq(min(msim), max(msim), length = 100),
mean = 1/lambda, sd = 1/lambda),
col = "blue", lwd = 2)
xnorm <- seq(min(msim), max(msim), length = 1000)
ynorm <- dnorm(xnorm, mean = 1/lambda, sd = 1/lambda)
hist(msim,
xlab = "Sample Mean",
main = "Histogram with Distribution of Sample Mean")
lines(xnorm, ynorm, col = "blue", lwd = 2)
plot(xnorm, ynorm, col = "blue", lwd = 2)
xnorm <- seq(min(0,min(msim)), max(msim), length = 1000)
ynorm <- dnorm(xnorm, mean = 1/lambda, sd = 1/lambda)
plot(xnorm, ynorm, col = "blue", lwd = 2)
xnorm <- seq(min(0,min(msim)), max(10, max(msim)), length = 1000)
ynorm <- dnorm(xnorm, mean = 1/lambda, sd = 1/lambda)
hist(msim, prob = TRUE, breaks = 30,
xlab = "Sample Mean",
main = "Histogram with Distribution of Sample Mean")
lines(xnorm, ynorm, col = "blue", lwd = 1)
hist(rexp(1000,0.2), breaks = 40)
hist(msim, breaks = 40)
hist(msim, breaks = 40, xlim = c(0,10))
hist(msim, breaks = 30, xlim = c(0,10))
hist(msim, prob = TRUE, breaks = 30, xlim = c(0,10))
hist(msim, prob = TRUE, breaks = 100, xlim = c(0,10))
dnorm(lrg.sample$rating, 5, 5)
hist(dnorm(lrg.sample$rating, 5, 5))
hist(dnorm(lrg.sample$rating, 5, 5), prob = TRUE, type = "l", lwd = 1)
plot(dnorm(lrg.sample$rating, 5, 5), prob = TRUE, type = "l", lwd = 1)
x <- c(0.18, -1.54, 0.42, 0.95)
w <- c(2, 1, 3, 1)
mean(x)
x_diff <- c((x - mean(x))^2)
calc1 <- c(x_diff*w)
sum(calc1)
sum(w)
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
install.packages("UsingR")
library(UsingR)
install.packages("manipulate")
library(manipulate)
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
sdX <- Sd(x)
sdX <- sd(x)
sdY <- sd(y)
avgX <- mean(x)
avgY <- mean(y)
lm(formula = (y - avgy) ~ (x - avgX) -1)
lm(formula = (y - avgY) ~ (x - avgX) -1)
lm(formula = (y - avgY) ~ (x - avgX))
lm((y - avgY) ~ (x - avgX))
lm(x~y)
lm(y~x)
mean(x)
mean(y)
var(x)
var(y)
sd(x)
sd(y)
cov(x, y)
cov(y, x)
lm(formula = l(y - avgY)~l(x-avgX)-1)
lm(formula = I(y - avgY)~I(x-avgX)-1)
data(mtcars)
fit(formula = mpg~weight, data = mtcars)
lm(mtcars$mpg~mtcars$weight)
str(mtcars)
lm(mtcars$mpg~mtcars$wt)
fit(formula = mpg~wt, data = mtcars)
x <- c(8.58, 10.46, 9.01, 9.64, 8.86)
x_norm <- c((x - mean(x)))
x_norm
mean(x)
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
lm(y~x)
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
mean(x)
1.5 / 0.4
x <- c(0.18, -1.54, 0.42, 0.95)
w <- c(2, 1, 3, 1)
avgX <- mean(x)
weightedX <- c(x*w)
mean(weightedX)
wtd.mean(x, weights = w)
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
lm(y~0+x)
x <- c(8.58, 10.46, 9.01, 9.64, 8.86)
mean(x)
sd(x)
x_centerd <- c((x - mean(x))/sd(x))
x_centerd
library(swirl)
swirl()
fit <- lm(child~parent, data = galton)
sum(resid(fit)^2)/(n-2)
sqrt(sum(resid(fit)^2)/(n-2))
sqrt(sum(fit$residuals^2) / (n - 2))
summary(fit)$sigma
sqrt(deviance(fit)/(n-2))
mu <- mean(galton$child)
sTot <- sum((galton%child - mu)^2)
sTot <- sum((galton%child - mu)^2)
sTot <- sum((galton$child - mu)^2)
sRes <- deviance(fit)
R^2 <- 1 - sRes/sTot
1 - sRes/sTot
summary(fit)$r.squared
cor(galton$child, $galton$parents)^2
cor(galton$child, galton$parents)^2
cor(galton$child, galton$parent)^2
ones <- rep(1, nrow(galton))
lm(child ~ ones + parent -1, galton)
lm(child ~ parent, galton)
lm(child ~ 1, galton)
view(trees)
head(trees)
fit <- lm(Volume ~ Girth + Height + Constant -1, trees)
trees2 <- eliminate("Girth", trees)
head(trees2)
fit2 <- lm(Volume ~ Height + Constant -1, trees2)
lapply(list(fit, fit2), coef)
lm(Fertility~all, data = "swiss")
lm(Fertility~all, "swiss")
lm(Fertility~., "swiss")
lm(Fertility~".", "swiss")
lm(Fertility~., data = "swiss")
lm(Fertility~., data = swiss)
all <- lm(Fertility ~ ., swiss)
summary(all)
summary(lm(Fertility~Agriculture, swiss))
cor(swiss$Examination, swiss$Education)
cor(swiss$Agriculture, swiss$Education)
View(makelms)
makelms()
ec <- sum(swiss$Examination, swiss$Catholic)
ec <- swiss$Examination + swiss$Catholic
efit <- lm(Fertility ~ . + ec, data = swiss)
all$coefficients - efit$coefficients
x <- c(0.61, 0.93, 0.83, 0.35, 0.54, 0.16, 0.91, 0.62, 0.62)
y <- c(0.67, 0.84, 0.6, 0.18, 0.85, 0.47, 1.1, 0.65, 0.36)
fit <- lm(y~x)
summary(fit)
data(mtcars)
head(mtcars)
fit <- lm(mpg~wt, mtcars)
?predict
predict(fit, newdata = mtcars, interval = "confidence", level = 0.95)
predict(fit, interval = "confidence", level = 0.95)
summary(fit)
mean(mtcars$wt)
avgwt <- data.frame(wt = mean(mtcars$wt))
predict(fit, avgwt, interval = "confidence", level = 0.95)
summary(fit)$coeff
predict(fit, newdata = 3, interval = "confidence", level = 0.95)
predict(fit, 3, interval = "confidence", level = 0.95)
newwt <- 3000 / 1000
newwt <- data.frame(wt = 3000 / 1000)
predict(fit, newwt, interval = "confidence", level = 0.95)
predict(fit, newwt, interval = "prediction", level = 0.95)
shortwt <- data.frame(wt = 2000/1000)
predict(fit, shortwt, interval = "confidence", level = 0.95)
24.82389-37.285126
28.36848-37.285126
data(mtcars)
fit <- lm(mpg~wt, data = mtcars)
fit2 <- lm(mpg~1, data = mtcars)
summary(fit)$coeff
summary(fit2)$coeff
predict(fit)
summary(fit)$r.squared
?deviance
deviance(fit)
library(swirl)
swirl()
rgp1()
rgp2()
head(swiss)
lm(Fertility ~ Agriculture + Examination + Education + Catholic + Infant.Mortality, data = swiss)
lm(Fertility ~ ., swiss)
lm(Fertility ~ ., swiss)
mdl <- lm(Fertility ~ ., swiss)
vif(mdl)
mdl2 <- lm(Fertility ~ Agriculture + Education + Catholic + Infant.Mortality, data = swiss)
vif(mdl2)
simbias()
xlc <- simbias()
x1c <- simbias()
apply(x1c, 1, mean)
fit1 <- lm(Fertility ~ Agriculture, data = swiss)
fit3 <- lm(Fertility ~ Agriculture + Examination + Eductation, data = swiss)
fit3 <- lm(Fertility ~ Agriculture + Examination + Education, data = swiss)
anova(fit1, fit3)
deviance(fit3)
d <- deviance(fit3)/43
n <- (deviance(fit1) - deviance(fit3))/2
n/d
pf(n/d, 2, 43, lower.tail=FALSE)
shapiro.test(fit3$residuals) to test the residual of fit3
shapiro.test(fit3$residuals)
anova(fit1, fit3, fit5, fit6)
ravenData
mdl <- lm(formula = ravenWinNum ~ ravenScore, family = "binomial", data = ravenData)
mdl <- lm(ravenWinNum ~ ravenScore, family = "binomial", data = ravenData)
mdl <- glm(ravenWinNum ~ ravenScore, family=binomial,
| data=ravenData)
mdl <- glm(ravenWinNum ~ ravenScore, family=binomial, data=ravenData)
predict(mdl, data.frame(ravenScore=c(0, 3, 6)))
lodds <- predict(mdl, data.frame(ravenScore=c(0, 3, 6)))
exp(lodds)/(1+exp(lodds))
summary(mdl)
confint(mdl)
exp(confint(mdl))
anova(mdl)
qchisq(0.95, 1)
var(rpois(1000, 50))
head(hits)
class(hits[,'date'])
as.integer(head(hits[,'date']))
mdl <- glm(visits ~ date, poisson, hits)
summary(mdl)
confint(mdl, 'date')
exp(confint(mdl, 'date'))
which.max(hits[,'visits'])
hits[704,]
mdl$fitted.values[704
)
mdl$fitted.values[704]
lambda <- mdl$fitted.values[704]
qpois(.95, lambda)
mdl2 <- offset = log(visits +1)
mdl2 <- offset = log(mdl$visits +1)
mdl2 <- offset = log(hits$visits +1)
mdl2 <- log(hits$visits +1)
swirl()
?glm
glm(visits ~ date, poisson, hits, offset = log(visits +1))
mdl2 <- glm(formula = simplystats ~ date, family = poisson, data = hits, offset = log(visits + 1))
qpois(.95, mdl2$fitted.values[704])
setwd("/Users/harridw/Development/Coursera/Course7/MotorTrend_MPG")
install.packages(c("checkmate", "contfrac", "deSolve", "dplyr", "fields", "Formula", "Hmisc", "htmlwidgets", "httpuv", "jsonlite", "maps", "matrixStats", "quantmod", "readr", "rgdal", "RMySQL", "sp", "spam", "survival", "tidyr", "TTR", "XML", "xts", "zoo"))
